# Phase 1: Technical Exploration & Feasibility

**Objective:** To investigate the "black box" technical challenges identified in Phase 0 and determine the specific libraries, mathematical approaches, and metrics required to build the solution.

---

## 1. The "Unknowns" & Research Questions

### A. Universal Input & Tooling

**The Problem:** The tool must accept any file format that produces sound (MP3, WAV, AAC, MP4, etc.), but I don't know if these files store sound in fundamentally different ways.

- **Question 1:** Is treating an MP3 file different from treating a WAV, AAC, or MP4 file? Do they require different code to "open" and read the sound?
- **Question 2:** If they are different, is there a single tool or "wrapper" that handles all these differences automatically, allowing my code to treat every input as the same raw sound data?
- **Findings:**
    - MP3 & ACC are **lossy** formats, which have ordinary sounds for human ear, but bad for computer algorithms, WAV is **lossless.**
    - MP4 & MKV are formats for **containers** where we can separate the audio from the video.
    - There’s a general library in python that can treat all audio formats without damaging quality which is `librosa` depending on the universal tool FFmpeg.
    - Separation process can result into some cuts and holes in the voice, so it needs to be regenerated by a bandwidth extension (BWE) at the end if the formats are lossy.
    - Pipeline is like following:
        
        Input (any type of audio file) → Universal Decoder (Librosa/FFmpeg) → Separating Algorithm (??) → Fixing Holes (BWE) → Cleaning Voice (??) → Output (Final data again).
        

### B. Separation Logic (The Core)

**The Problem:** We need to distinguish "Voice" from "Music," but I don't know how a computer perceives that difference.

- **Question 3:** What are the distinguishing characteristics that make a "voice" different from "music" or "noise" to a computer?
- **Question 4:** What are the standard approaches or logical methods used in software to separate these two distinct sounds?
- **Findings:**
    - We can distinguish vocals from music using frequency domain, then by masking we can take only what we need.
    - Approaches:
        - **DSP (Digital Signal Processing):**
            - For Stereo sounds: it will work, because vocals are centered (equal in the right & left speakers) and instruments are panned to the sides, so mathematically it’s possible to distinguish between them.
            - **Failure Cases:**
                - Mono sounds: where drums can be centered too so it can’t distinguish between voice and drums sounds.
                - Also When a singer is in a big hall, where there’s a reverb or echo it fails to subtract the echo from the signal because Left ≠ Right any more.
        - **NMF (Non-negative Matrix Factorization) (Unsupervised Learning)**
            - Using statistical algebra we assume that a song is made up of a few repeating "sound dictionaries" (like a drum hit or a piano chord). It tries to factor the spectrogram matrix $V$ into two smaller matrices $W$ (patterns) and $H$ (activations).
            - It requires the algorithm to "learn" the song from scratch every time. It is slow and struggles with complex vocals that change pitch constantly.
        - **Deep Learning (Supervised Learning)**
            - The model is shown millions of pairs, it learns the *texture* of a voice. It learns that "wavy horizontal lines around 300Hz-3kHz" are usually human, while "rigid vertical lines" are drums, so it can easily distinguish.
                - **Three Known Architectures Maybe Experimented:**
                    1. CNNs / U-Nets (Frequency Domain).
                    2. RNNs / LSTMs (Sequence Modeling).
                    3. Hybrid / Time-Domain (The State-of-the-Art).
                    

### C. Quality Preservation

**The Problem:** I suspect that removing part of the sound might damage the part I want to keep.

- **Question 5:** Does the process of stripping away background noise inevitably damage or "cut" parts of the voice?
- **Question 6:** If damage occurs, what does it sound like, and are there known ways to minimize it?
- **Findings:** *(To be filled during research)*

### D. The "Cocktail Party" Problem (Voice vs. Voice)

**The Problem:** Sometimes the "noise" isn't music, but other people talking.

- **Question 7:** If we can successfully clean a human voice from instruments, does that same approach work for separating a specific human voice from *other* background voices?
- **Findings:** *(To be filled during research)*

### E. Amplification

**The Problem:** I need to make the voice louder, but I don't know how to do it without making it sound bad or boosting the noise I just tried to remove.

- **Question 8:** How do we programmatically amplify a sound file?
- **Question 9:** How do we ensure that increasing the volume doesn't cause distortion or make any remaining background noise overwhelmingly loud?
- **Findings:** *(To be filled during research)*

---

## 2. Feasibility Decision (To be filled at end of Phase 1)

- **Selected Tech Stack:**
- **Selected Approach:**
- **Go/No-Go Decision:**
